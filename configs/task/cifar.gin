import train
import dataloader

import archs.s5.ssm
from archs import seq_layer
from archs import seq_model

D_MODEL = 512                       # overrides ssm/size/{}.gin
SSM_SIZE_BASE = 384                 # overrides ssm/s5.gin
NUM_BLOCKS = 3                      # overrides ssm/s5.gin

TASK_NAME = 'cifar'                 # dummy
BATCH_SIZE = 64                     # overrides base.gin

NUM_STEPS = 4_000_000              # overrides base.gin
NUM_WARMUP_STEPS = 30_000

DROPOUT = 0.1                       # overrides base.gin
BATCHNORM = True                    # overrides base.gin

S5_OPT_CONFIG = "BfastandCdecay"    # overrides ssm/s5.gin

# ---------- S5 Specific ---------
archs.s5.ssm.S5:
    C_init = "lecun_normal"
    bidirectional = True
# --------------------------------

seq_layer.SequenceLayer:
    activation = 'half_glu2'

train.Trainer:
    create_dataset_fn = @dataloader.create_lra_image_classification_dataset

dataloader.create_lra_image_classification_dataset:
    bsz = %BATCH_SIZE

seq_model.ClassificationModel:
    padded = False
